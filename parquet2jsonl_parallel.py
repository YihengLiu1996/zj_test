import os
import multiprocessing as mp
from pathlib import Path
import pyarrow.parquet as pq
import orjson
import gc

def parquet_to_jsonl_task(args):
    """
    å•æ–‡ä»¶è½¬æ¢ä»»åŠ¡ï¼ˆå…³é—­ GCï¼Œæé€Ÿæ¨¡å¼ï¼‰
    """
    parquet_path, output_root, input_root = args
    try:
        # å…³é—­å­è¿›ç¨‹ GCï¼Œæå‡æ€§èƒ½
        gc.disable()

        # è®¡ç®—è¾“å‡ºè·¯å¾„ï¼ˆä¿æŒç»“æ„ï¼‰
        rel_path = os.path.relpath(parquet_path, input_root)
        jsonl_rel_path = Path(rel_path).with_suffix('.jsonl')
        output_path = Path(output_root) / jsonl_rel_path
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # ä½¿ç”¨ PyArrow è¯»å–æ•´è¡¨ï¼ˆå†…å­˜å……è¶³ï¼Œç›´æ¥å…¨è¯»ï¼‰
        table = pq.read_table(parquet_path)
        # è½¬ä¸º RecordBatchï¼ˆæ›´é«˜æ•ˆï¼‰
        batches = table.to_batches()
        lines = []

        # æ‰¹é‡åºåˆ—åŒ–ä¸º JSONL è¡Œ
        for batch in batches:
            for i in range(batch.num_rows):
                row_dict = {}
                for col in batch.column_names:
                    val = batch[col][i].as_py()
                    row_dict[col] = val
                # orjson åºåˆ—åŒ– + æ¢è¡Œ
                line = orjson.dumps(row_dict, option=orjson.OPT_APPEND_NEWLINE)
                lines.append(line)

        # ä¸€æ¬¡æ€§å†™å…¥ï¼ˆæœ€å¤§åŒ– I/O ååï¼‰
        with open(output_path, 'wb') as f:
            f.writelines(lines)

        # é‡æ–°å¯ç”¨ GCï¼ˆå¯é€‰ï¼Œè¿›ç¨‹å³å°†é€€å‡ºï¼‰
        gc.enable()
        return f"âœ… {parquet_path}"

    except Exception as e:
        return f"âŒ {parquet_path} | {e}"


def find_parquet_files_fast(root_dir):
    """
    ä½¿ç”¨ os.scandir é€’å½’æŸ¥æ‰¾ .parquet æ–‡ä»¶ï¼ˆæ›´å¿«ï¼‰
    """
    parquet_files = []
    stack = [root_dir]
    while stack:
        current_dir = stack.pop()
        try:
            with os.scandir(current_dir) as it:
                for entry in it:
                    if entry.is_file() and entry.name.lower().endswith('.parquet'):
                        parquet_files.append(entry.path)
                    elif entry.is_dir():
                        stack.append(entry.path)
        except PermissionError:
            continue
    return parquet_files


def main():
    input_folder = input("ğŸ“¥ è¯·è¾“å…¥åŒ…å« parquet æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„: ").strip()
    output_folder = input("ğŸ“¤ è¯·è¾“å…¥è¾“å‡º jsonl æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„: ").strip()

    if not os.path.exists(input_folder):
        print("âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼")
        return

    Path(output_folder).mkdir(parents=True, exist_ok=True)

    print("ğŸ” æ­£åœ¨æ‰«æ parquet æ–‡ä»¶...")
    parquet_files = find_parquet_files_fast(input_folder)

    if not parquet_files:
        print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½• .parquet æ–‡ä»¶ï¼")
        return

    total_files = len(parquet_files)
    print(f"ğŸš€ æ‰¾åˆ° {total_files} ä¸ªæ–‡ä»¶ï¼Œå¯åŠ¨ {mp.cpu_count()} è¿›ç¨‹å¹¶è¡Œè½¬æ¢...")

    # æ„å»ºä»»åŠ¡å‚æ•°
    tasks = [(f, output_folder, input_folder) for f in parquet_files]

    # åˆ›å»ºè¿›ç¨‹æ± ï¼ˆé»˜è®¤ CPU æ ¸æ•°ï¼‰
    with mp.Pool(processes=mp.cpu_count()) as pool:
        results = pool.map(parquet_to_jsonl_task, tasks)

    # æ‰“å°ç»“æœæ‘˜è¦ï¼ˆé¿å…é€è¡Œ print å½±å“æ€§èƒ½ï¼‰
    success_count = sum(1 for r in results if r.startswith('âœ…'))
    print(f"\nğŸ‰ è½¬æ¢å®Œæˆï¼æˆåŠŸ: {success_count} / {total_files}")
    if success_count < total_files:
        print("â— ä»¥ä¸‹æ–‡ä»¶è½¬æ¢å¤±è´¥:")
        for r in results:
            if r.startswith('âŒ'):
                print(r)


if __name__ == "__main__":
    mp.freeze_support()  # Windows å…¼å®¹
    main()
